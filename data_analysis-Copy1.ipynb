{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## imported simple json over json as it is faster\n",
    "import simplejson as json\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file=\"gabai.0013.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reading line by line as the file has erros  and only valid json objects need to be added ot the list, Also the file is large so it saves memmory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49999\n",
      "99999\n",
      "149999\n",
      "199999\n",
      "249999\n",
      "299999\n",
      "349999\n",
      "399999\n",
      "449999\n",
      "499999\n",
      "549999\n",
      "599999\n",
      "649999\n",
      "699999\n",
      "749999\n",
      "799999\n",
      "849999\n",
      "Error at line number 872991\n",
      "Error at line number 872992\n",
      "Error at line number 872993\n",
      "Error at line number 872994\n",
      "Error at line number 872995\n",
      "Error at line number 872996\n",
      "Error at line number 872997\n",
      "Error at line number 872998\n",
      "Error at line number 872999\n",
      "Error at line number 873000\n",
      "Error at line number 873001\n",
      "Error at line number 873002\n",
      "Error at line number 873003\n",
      "Error at line number 873004\n",
      "Error at line number 873005\n",
      "Error at line number 873006\n",
      "Error at line number 873007\n",
      "Error at line number 873008\n",
      "Error at line number 873009\n",
      "Error at line number 873010\n",
      "Error at line number 873011\n",
      "Error at line number 873012\n",
      "Error at line number 873013\n",
      "Error at line number 873014\n",
      "Error at line number 873015\n",
      "Error at line number 873016\n",
      "Error at line number 873017\n",
      "Error at line number 873018\n",
      "Error at line number 873019\n",
      "Error at line number 873020\n",
      "Error at line number 873021\n",
      "Error at line number 873022\n",
      "Error at line number 873023\n",
      "Error at line number 873024\n",
      "Error at line number 873025\n",
      "Error at line number 873026\n",
      "Error at line number 873027\n",
      "Error at line number 873028\n",
      "Error at line number 873029\n",
      "Error at line number 873030\n",
      "899999\n",
      "949999\n",
      "999999\n",
      "CPU times: user 1min 25s, sys: 2min 13s, total: 3min 39s\n",
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ls=[]\n",
    "with open(input_file) as f:\n",
    "    for i,line in enumerate(f):\n",
    "        try:\n",
    "            c_line=json.loads(line)\n",
    "            ls.append(c_line)\n",
    "            if((i+1)%50000==0):\n",
    "                print(i)\n",
    "        except:\n",
    "            print(\"Error at line number\",i)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Inspecting Lines where error occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<br />\n",
      "\n",
      "<b>Warning</b>:  require(/home/forge/gab.ai/bootstrap/../vendor/autoload.php): failed to open stream: No such file or directory in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Fatal error</b>:  require(): Failed opening required '/home/forge/gab.ai/bootstrap/../vendor/autoload.php' (include_path='.:/usr/share/php') in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Warning</b>:  require(/home/forge/gab.ai/bootstrap/../vendor/autoload.php): failed to open stream: No such file or directory in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Fatal error</b>:  require(): Failed opening required '/home/forge/gab.ai/bootstrap/../vendor/autoload.php' (include_path='.:/usr/share/php') in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Warning</b>:  require(/home/forge/gab.ai/bootstrap/../vendor/autoload.php): failed to open stream: No such file or directory in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Fatal error</b>:  require(): Failed opening required '/home/forge/gab.ai/bootstrap/../vendor/autoload.php' (include_path='.:/usr/share/php') in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Warning</b>:  require(/home/forge/gab.ai/bootstrap/../vendor/autoload.php): failed to open stream: No such file or directory in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Fatal error</b>:  require(): Failed opening required '/home/forge/gab.ai/bootstrap/../vendor/autoload.php' (include_path='.:/usr/share/php') in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Warning</b>:  require(/home/forge/gab.ai/bootstrap/../vendor/autoload.php): failed to open stream: No such file or directory in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Fatal error</b>:  require(): Failed opening required '/home/forge/gab.ai/bootstrap/../vendor/autoload.php' (include_path='.:/usr/share/php') in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Warning</b>:  require(/home/forge/gab.ai/bootstrap/../vendor/autoload.php): failed to open stream: No such file or directory in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Fatal error</b>:  require(): Failed opening required '/home/forge/gab.ai/bootstrap/../vendor/autoload.php' (include_path='.:/usr/share/php') in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Warning</b>:  require(/home/forge/gab.ai/bootstrap/../vendor/autoload.php): failed to open stream: No such file or directory in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Fatal error</b>:  require(): Failed opening required '/home/forge/gab.ai/bootstrap/../vendor/autoload.php' (include_path='.:/usr/share/php') in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Warning</b>:  require(/home/forge/gab.ai/bootstrap/../vendor/autoload.php): failed to open stream: No such file or directory in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "<br />\n",
      "\n",
      "<b>Fatal error</b>:  require(): Failed opening required '/home/forge/gab.ai/bootstrap/../vendor/autoload.php' (include_path='.:/usr/share/php') in <b>/home/forge/gab.ai/bootstrap/autoload.php</b> on line <b>17</b><br />\n",
      "\n",
      "CPU times: user 4.17 s, sys: 5.29 s, total: 9.46 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(input_file) as f:\n",
    "    lines = f.readlines()\n",
    "for i in range(872991,873030):\n",
    "    print(lines[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we have confirmed the fact that we have not missed any useful  message \n",
    "### I also tried by changing the range at random to add more sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 s, sys: 44.2 s, total: 1min 1s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## loading the list into a dataframe now.\n",
    "df=pd.DataFrame(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  How many messages/gabs are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages is 999992\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of messages is\", len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 189400,\n",
       " 'is_donor': False,\n",
       " 'is_investor': False,\n",
       " 'is_premium': False,\n",
       " 'is_private': False,\n",
       " 'is_pro': False,\n",
       " 'name': 'HenPre13',\n",
       " 'picture_url': 'https://files.gab.ai/user/59392bee3268b.jpg',\n",
       " 'username': 'Zwitscher',\n",
       " 'verified': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Explpring the user, we need to create a  new user column with the information of the curtrent dict.\n",
    "df.loc[1].user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 28.2 s, total: 38.6 s\n",
      "Wall time: 53.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##making a new data frame where we have expanded the user column and preffixxed the column name with user_\n",
    "user_df = pd.concat([df.drop('user', axis=1), pd.DataFrame(df['user'].tolist()).add_prefix('user_')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many users authored messages are in this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages is 15973\n"
     ]
    }
   ],
   "source": [
    "## number of users\n",
    "print(\"Number of users is\", len(user_df['user_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  What are the mean/median/max/min number of messages authored by a user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " User  Message Stats:\n",
      " Mean: 62.60514618418581 \n",
      " Median: 4.0 \n",
      " Max: 13799 \n",
      " Min: 1\n"
     ]
    }
   ],
   "source": [
    "### mean/median/max/min number of messages authored by a user\n",
    "grouped_user_df = user_df.groupby(['user_id']).user_id.count()\n",
    "print(\" User  Message Stats:\\n Mean: {} \\n Median: {} \\n Max: {} \\n Min: {}\".format( \\\n",
    "      grouped_user_df.mean(), grouped_user_df.median(), \\\n",
    "     grouped_user_df.max() , grouped_user_df.min())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the 10 users with the most messages, and the number of messages each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\t\t\tUser_ID\tCount\n",
      "\n",
      "Constitutional Drunk\t64690\t13799\n",
      "EyeAm               \t69650\t5996\n",
      "Ron MacDonald       \t100406\t5471\n",
      "#NSFW LeeLee        \t102726\t4956\n",
      "Jay                 \t169891\t4842\n",
      "Tipol J News        \t167852\t4816\n",
      "OpenQuotes üëåüê∏       \t98146\t4678\n",
      "Dani                \t105504\t4594\n",
      "bobofkake-Bro:)     \t29492\t4404\n",
      "Lea Morabito        \t77796\t4230\n",
      "CPU times: user 27.1 ms, sys: 31.3 ms, total: 58.3 ms\n",
      "Wall time: 93.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# top 10 users with messages\n",
    "top10_df_series = grouped_user_df.nlargest(10)\n",
    "#search user id in user_df, \n",
    "print(\"Name\\t\\t\\tUser_ID\\tCount\\n\")\n",
    "for x,y in top10_df_series.iteritems():\n",
    "    ### can be optimezed look into it\n",
    "    c_id = (user_df.user_id.values == x).argmax()\n",
    "    c_user_name = user_df.loc[c_id].user_name\n",
    "    print('{:<20}\\t{}\\t{}'.format(c_user_name,x,y))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL MINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "the web url matching regex used by markdown\n",
    "http://daringfireball.net/2010/07/improved_regex_for_matching_urls\n",
    "https://gist.github.com/gruber/8891611\n",
    "\"\"\"\n",
    "URL_REGEX = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?¬´¬ª‚Äú‚Äù‚Äò‚Äô])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "message_list= user_df['body'].tolist()\n",
    "urls=[]\n",
    "for message in message_list:\n",
    "    a=re.findall(URL_REGEX,message.lower())\n",
    "    urls.extend(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 most common urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL  Count\n",
      "gab.ai 880\n",
      "mewe.com/join/lovehaswon 874\n",
      "https://www.abgeordneten-check.de/kampagnen/stoppt-die-digitale-zensur/startseite/aktion/368383z13871/nc/1/ 441\n",
      "military.com 384\n",
      "kek.gg 323\n"
     ]
    }
   ],
   "source": [
    "url_counter=Counter(urls)\n",
    "top_5_urls = url_counter.most_common(5)\n",
    "print(\"URL  Count\")\n",
    "for url,count in top_5_urls:\n",
    "    print(url,count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Mining for frequently occuring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "all_words=[]\n",
    "all_alpha_words=[]\n",
    "\n",
    "stop_words = set(line.strip() for line in open('stop_words.txt'))\n",
    "stop_words.add(\"https\")\n",
    "stop_words.add(\"http\")\n",
    "\n",
    "for message in message_list:\n",
    "    message=message.lower()\n",
    "    tokens = word_tokenize(message)\n",
    "    filtered_words = [w for w in tokens if not w in stop_words]\n",
    "    alnum_words = [w for w in filtered_words if w.isalnum()]\n",
    "    alpha_words = [w for w in alnum_words if w.isalpha() ]\n",
    "    all_words.extend(alnum_words)\n",
    "    all_alpha_words.extend(alpha_words)\n",
    "    \n",
    "words_counter = Counter(all_words)\n",
    "alpha_words_counter = Couter(all_alpha_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 most common alphanumeric words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2017', 121158), ('news', 79251), ('trump', 73970), ('watch', 67800), ('youtube', 64861), ('die', 59887), ('07', 57012), ('06', 56197), ('people', 44484), ('der', 42965)]\n"
     ]
    }
   ],
   "source": [
    "top_10_words = words_counter.most_common(10)\n",
    "print(top_10_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 10 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count By Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###time zone issue ?\n",
    "%%time\n",
    "user_date_time = pd.to_datetime(user_df['created_at'],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 930 ms, total: 11.8 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "user_date=user_date_time.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_counts= user_date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mark_ra",
   "language": "python",
   "name": "mark_ra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
